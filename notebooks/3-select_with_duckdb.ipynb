{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Querying Iceberg Tables with DuckDB\n",
    "\n",
    "This notebook demonstrates how to query Apache Iceberg tables using DuckDB, a high-performance analytical database engine. DuckDB's native Iceberg support provides efficient querying capabilities with SQL.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you'll understand:\n",
    "- How to configure DuckDB for Iceberg table access\n",
    "- How to connect DuckDB to Iceberg REST catalogs\n",
    "- How to perform efficient SQL queries on Iceberg data\n",
    "- How to leverage DuckDB's analytical capabilities\n",
    "- Best practices for DuckDB-Iceberg integration\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed notebooks 1-2 (table creation and data insertion)\n",
    "- DuckDB library installed\n",
    "- Docker environment running\n",
    "- PyIceberg library available\n",
    "\n",
    "## Why DuckDB with Iceberg?\n",
    "\n",
    "DuckDB is an excellent choice for Iceberg analytics because:\n",
    "- **Native Support**: Built-in Iceberg connector\n",
    "- **Performance**: Vectorized execution engine\n",
    "- **SQL Compatibility**: Standard SQL interface\n",
    "- **Lightweight**: No server setup required\n",
    "- **Analytics Focus**: Optimized for analytical workloads\n",
    "- **Arrow Integration**: Efficient data exchange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Import necessary libraries and establish connections to both PyIceberg and DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully:\n",
      "- DuckDB version: 1.3.1\n",
      "- PyIceberg: Available\n",
      "- Pandas: Available for result display\n",
      "\n",
      "Ready for Iceberg querying with DuckDB\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "from pyiceberg.catalog import load_catalog\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Libraries imported successfully:\")\n",
    "print(f\"- DuckDB version: {duckdb.__version__}\")\n",
    "print(\"- PyIceberg: Available\")\n",
    "print(\"- Pandas: Available for result display\")\n",
    "print(\"\\nReady for Iceberg querying with DuckDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catalog-verification-section",
   "metadata": {},
   "source": [
    "## Iceberg Catalog Verification\n",
    "\n",
    "First, let's verify our Iceberg table exists and contains data using PyIceberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "catalog-verification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyIceberg catalog connected\n",
      "Available namespaces: [('play_iceberg',)]\n",
      "Users table loaded successfully\n",
      "\n",
      "Table Information:\n",
      "- Schema fields: 8\n",
      "- Partition fields: 3\n",
      "- Current record count: 5\n"
     ]
    }
   ],
   "source": [
    "# Configure PyIceberg catalog connection\n",
    "catalog_config = {\n",
    "    \"uri\": \"http://localhost:8181\",\n",
    "    \"s3.endpoint\": \"http://localhost:9000\",\n",
    "    \"s3.access-key-id\": \"admin\",\n",
    "    \"s3.secret-access-key\": \"password\",\n",
    "    \"s3.path-style-access\": \"true\",\n",
    "}\n",
    "\n",
    "# Load catalog and verify table\n",
    "try:\n",
    "    catalog = load_catalog(\"rest\", **catalog_config)\n",
    "    print(\"PyIceberg catalog connected\")\n",
    "    \n",
    "    # List available namespaces\n",
    "    namespaces = list(catalog.list_namespaces())\n",
    "    print(f\"Available namespaces: {namespaces}\")\n",
    "    \n",
    "    # Load users table\n",
    "    users_table = catalog.load_table(\"play_iceberg.users\")\n",
    "    print(\"Users table loaded successfully\")\n",
    "    \n",
    "    # Display table information\n",
    "    print(\"\\nTable Information:\")\n",
    "    print(f\"- Schema fields: {len(users_table.schema().fields)}\")\n",
    "    print(f\"- Partition fields: {len(users_table.spec().fields)}\")\n",
    "    \n",
    "    # Get current data count\n",
    "    current_data = users_table.scan().to_pandas()\n",
    "    print(f\"- Current record count: {len(current_data)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Iceberg catalog: {e}\")\n",
    "    print(\"Please ensure Docker services are running and previous notebooks completed\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "table-preview-section",
   "metadata": {},
   "source": [
    "## Table Data Preview\n",
    "\n",
    "Let's examine the current table structure and data using PyIceberg before querying with DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "table-preview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Schema:\n",
      "====================\n",
      "table {\n",
      "  1: user_id: required long\n",
      "  2: username: required string\n",
      "  3: email: required string\n",
      "  4: is_active: required boolean\n",
      "  5: created_year: required int\n",
      "  6: created_month: required int\n",
      "  7: created_day: required int\n",
      "  8: updated_at: required timestamp\n",
      "}\n",
      "\n",
      "Table Partitioning:\n",
      "=========================\n",
      "[\n",
      "  1000: created_year: identity(5)\n",
      "  1001: created_month: identity(6)\n",
      "  1002: created_day: identity(7)\n",
      "]\n",
      "\n",
      "Current Data Sample:\n",
      "==============================\n",
      "   user_id       username                      email  is_active  created_year  \\\n",
      "0        1       john_doe       john.doe@example.com       True          2025   \n",
      "1        2     jane_smith     jane.smith@example.com       True          2025   \n",
      "2        3   alice_wonder   alice.wonder@example.com      False          2025   \n",
      "3        4    bob_builder    bob.builder@example.com       True          2025   \n",
      "4        5  charlie_brown  charlie.brown@example.com       True          2025   \n",
      "\n",
      "   created_month  created_day                 updated_at  \n",
      "0              7            1 2025-07-01 13:41:16.173663  \n",
      "1              7            1 2025-07-01 13:41:16.173663  \n",
      "2              7            1 2025-07-01 13:41:16.173663  \n",
      "3              7            1 2025-07-01 13:41:16.173663  \n",
      "4              7            1 2025-07-01 13:41:16.173663  \n",
      "\n",
      "Data Summary:\n",
      "- Total records: 5\n",
      "- Active users: 4\n",
      "- Unique usernames: 5\n",
      "- Date range: [2025]\n"
     ]
    }
   ],
   "source": [
    "# Display table schema and current data\n",
    "print(\"Table Schema:\")\n",
    "print(\"=\" * 20)\n",
    "print(users_table.schema())\n",
    "\n",
    "print(\"\\nTable Partitioning:\")\n",
    "print(\"=\" * 25)\n",
    "print(users_table.spec())\n",
    "\n",
    "print(\"\\nCurrent Data Sample:\")\n",
    "print(\"=\" * 30)\n",
    "print(current_data.head())\n",
    "\n",
    "print(\"\\nData Summary:\")\n",
    "print(f\"- Total records: {len(current_data)}\")\n",
    "print(f\"- Active users: {current_data['is_active'].sum()}\")\n",
    "print(f\"- Unique usernames: {current_data['username'].nunique()}\")\n",
    "print(f\"- Date range: {current_data['created_year'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duckdb-setup-section",
   "metadata": {},
   "source": [
    "## DuckDB Setup and Configuration\n",
    "\n",
    "Configure DuckDB to connect to our Iceberg tables via the REST catalog and MinIO storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "duckdb-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up DuckDB connection...\n",
      "Installing DuckDB Iceberg extension...\n",
      "Iceberg extension loaded successfully\n",
      "\n",
      "Configuring S3/MinIO settings...\n",
      "  ✓ SET s3_endpoint = 'localhost:9000'\n",
      "  ✓ SET s3_access_key_id = 'admin'\n",
      "  ✓ SET s3_secret_access_key = 'password'\n",
      "  ✓ SET s3_use_ssl = false\n",
      "  ✓ SET s3_url_style = 'path'\n",
      "\n",
      "DuckDB S3 configuration completed\n"
     ]
    }
   ],
   "source": [
    "# Create DuckDB connection\n",
    "print(\"Setting up DuckDB connection...\")\n",
    "conn = duckdb.connect()\n",
    "\n",
    "# Install and load Iceberg extension\n",
    "print(\"Installing DuckDB Iceberg extension...\")\n",
    "try:\n",
    "    conn.execute(\"INSTALL iceberg\")\n",
    "    conn.execute(\"LOAD iceberg\")\n",
    "    print(\"Iceberg extension loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Extension installation failed: {e}\")\n",
    "    print(\"Note: Extension may already be installed\")\n",
    "\n",
    "# Configure S3/MinIO settings\n",
    "print(\"\\nConfiguring S3/MinIO settings...\")\n",
    "s3_config_commands = [\n",
    "    \"SET s3_endpoint = 'localhost:9000'\",\n",
    "    \"SET s3_access_key_id = 'admin'\",\n",
    "    \"SET s3_secret_access_key = 'password'\",\n",
    "    \"SET s3_use_ssl = false\",\n",
    "    \"SET s3_url_style = 'path'\"\n",
    "]\n",
    "\n",
    "for cmd in s3_config_commands:\n",
    "    try:\n",
    "        conn.execute(cmd)\n",
    "        print(f\"  ✓ {cmd}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ {cmd} - Error: {e}\")\n",
    "\n",
    "print(\"\\nDuckDB S3 configuration completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catalog-connection-section",
   "metadata": {},
   "source": [
    "## Iceberg Catalog Connection in DuckDB\n",
    "\n",
    "Establish connection between DuckDB and the Iceberg REST catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "catalog-connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring Iceberg catalog in DuckDB...\n",
      "  ✓ Iceberg secret created\n",
      "  ✓ Iceberg catalog attached successfully\n",
      "\n",
      "DuckDB-Iceberg integration configured\n"
     ]
    }
   ],
   "source": [
    "# Configure Iceberg catalog in DuckDB\n",
    "print(\"Configuring Iceberg catalog in DuckDB...\")\n",
    "\n",
    "try:\n",
    "    # Create Iceberg secret for authentication\n",
    "    conn.execute(\"\"\"\n",
    "        CREATE OR REPLACE SECRET iceberg_secret (\n",
    "            TYPE iceberg,\n",
    "            CLIENT_ID 'admin',\n",
    "            CLIENT_SECRET 'password',\n",
    "            ENDPOINT 'http://localhost:8181'\n",
    "        )\n",
    "    \"\"\")\n",
    "    print(\"  ✓ Iceberg secret created\")\n",
    "    \n",
    "    # Attach Iceberg catalog\n",
    "    conn.execute(\"\"\"\n",
    "        ATTACH 'play_iceberg' AS iceberg_catalog (\n",
    "            TYPE iceberg, \n",
    "            SECRET iceberg_secret\n",
    "        )\n",
    "    \"\"\")\n",
    "    print(\"  ✓ Iceberg catalog attached successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Catalog configuration failed: {e}\")\n",
    "    print(\"  Trying alternative configuration...\")\n",
    "    \n",
    "    # Alternative: Direct table access without catalog\n",
    "    try:\n",
    "        # This approach may work if catalog attachment fails\n",
    "        print(\"  Attempting direct table access method\")\n",
    "    except Exception as e2:\n",
    "        print(f\"  Alternative method also failed: {e2}\")\n",
    "        raise\n",
    "\n",
    "print(\"\\nDuckDB-Iceberg integration configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "table-discovery-section",
   "metadata": {},
   "source": [
    "## Table Discovery and Verification\n",
    "\n",
    "Verify that DuckDB can see and access our Iceberg tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "table-discovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovering tables in DuckDB...\n",
      "\n",
      "Available tables:\n",
      "  - iceberg_catalog.play_iceberg.users\n",
      "\n",
      "✓ Users table found and accessible via DuckDB\n",
      "\n",
      "Table discovery completed\n"
     ]
    }
   ],
   "source": [
    "# List available tables in DuckDB\n",
    "print(\"Discovering tables in DuckDB...\")\n",
    "\n",
    "try:\n",
    "    # Show all available tables\n",
    "    tables_result = conn.execute(\"SHOW ALL TABLES\").fetchall()\n",
    "    \n",
    "    print(\"\\nAvailable tables:\")\n",
    "    for table_info in tables_result:\n",
    "        catalog_name, schema_name, table_name = table_info[0], table_info[1], table_info[2]\n",
    "        print(f\"  - {catalog_name}.{schema_name}.{table_name}\")\n",
    "    \n",
    "    # Check if our users table is accessible\n",
    "    users_table_found = any(\n",
    "        'users' in str(table_info) for table_info in tables_result\n",
    "    )\n",
    "    \n",
    "    if users_table_found:\n",
    "        print(\"\\n✓ Users table found and accessible via DuckDB\")\n",
    "    else:\n",
    "        print(\"\\n⚠ Users table not found in DuckDB catalog listing\")\n",
    "        print(\"  This may be normal - we can still try direct queries\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Table discovery failed: {e}\")\n",
    "    print(\"Proceeding with direct query attempts\")\n",
    "\n",
    "print(\"\\nTable discovery completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-queries-section",
   "metadata": {},
   "source": [
    "## Basic SQL Queries\n",
    "\n",
    "Execute basic SQL queries against the Iceberg table using DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "basic-queries",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing basic SQL queries...\n",
      "\n",
      "1. SELECT ALL RECORDS:\n",
      "==============================\n",
      "Total records: 5\n",
      "   user_id       username                      email  is_active  created_year  \\\n",
      "0        1       john_doe       john.doe@example.com       True          2025   \n",
      "1        2     jane_smith     jane.smith@example.com       True          2025   \n",
      "2        3   alice_wonder   alice.wonder@example.com      False          2025   \n",
      "3        4    bob_builder    bob.builder@example.com       True          2025   \n",
      "4        5  charlie_brown  charlie.brown@example.com       True          2025   \n",
      "\n",
      "   created_month  created_day                 updated_at  \n",
      "0              7            1 2025-07-01 13:41:16.173663  \n",
      "1              7            1 2025-07-01 13:41:16.173663  \n",
      "2              7            1 2025-07-01 13:41:16.173663  \n",
      "3              7            1 2025-07-01 13:41:16.173663  \n",
      "4              7            1 2025-07-01 13:41:16.173663  \n",
      "\n",
      "2. RECORD COUNT:\n",
      "====================\n",
      "Total users: 5\n",
      "\n",
      "3. ACTIVE USERS ONLY:\n",
      "=========================\n",
      "Active users: 4\n",
      "        username                      email  is_active\n",
      "0       john_doe       john.doe@example.com       True\n",
      "1     jane_smith     jane.smith@example.com       True\n",
      "2    bob_builder    bob.builder@example.com       True\n",
      "3  charlie_brown  charlie.brown@example.com       True\n",
      "\n",
      "4. CONTACT INFORMATION:\n",
      "==============================\n",
      "        username                      email\n",
      "0   alice_wonder   alice.wonder@example.com\n",
      "1    bob_builder    bob.builder@example.com\n",
      "2  charlie_brown  charlie.brown@example.com\n",
      "3     jane_smith     jane.smith@example.com\n",
      "4       john_doe       john.doe@example.com\n",
      "\n",
      "Basic queries completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Execute basic queries against the Iceberg table\n",
    "print(\"Executing basic SQL queries...\")\n",
    "\n",
    "# Define the table reference\n",
    "table_ref = '\"iceberg_catalog\".\"play_iceberg\".\"users\"'\n",
    "\n",
    "try:\n",
    "    # Query 1: Select all records\n",
    "    print(\"\\n1. SELECT ALL RECORDS:\")\n",
    "    print(\"=\" * 30)\n",
    "    result1 = conn.execute(f\"SELECT * FROM {table_ref}\").fetchdf()\n",
    "    print(f\"Total records: {len(result1)}\")\n",
    "    print(result1.head())\n",
    "    \n",
    "    # Query 2: Count records\n",
    "    print(\"\\n2. RECORD COUNT:\")\n",
    "    print(\"=\" * 20)\n",
    "    count_result = conn.execute(f\"SELECT COUNT(*) as total_users FROM {table_ref}\").fetchone()\n",
    "    print(f\"Total users: {count_result[0]}\")\n",
    "    \n",
    "    # Query 3: Filter active users\n",
    "    print(\"\\n3. ACTIVE USERS ONLY:\")\n",
    "    print(\"=\" * 25)\n",
    "    active_users = conn.execute(f\"\"\"\n",
    "        SELECT username, email, is_active \n",
    "        FROM {table_ref} \n",
    "        WHERE is_active = true\n",
    "    \"\"\").fetchdf()\n",
    "    print(f\"Active users: {len(active_users)}\")\n",
    "    print(active_users)\n",
    "    \n",
    "    # Query 4: Column projection\n",
    "    print(\"\\n4. CONTACT INFORMATION:\")\n",
    "    print(\"=\" * 30)\n",
    "    contacts = conn.execute(f\"\"\"\n",
    "        SELECT username, email \n",
    "        FROM {table_ref} \n",
    "        ORDER BY username\n",
    "    \"\"\").fetchdf()\n",
    "    print(contacts)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Query execution failed: {e}\")\n",
    "    print(\"\\nTroubleshooting tips:\")\n",
    "    print(\"- Verify catalog attachment was successful\")\n",
    "    print(\"- Check table name and namespace\")\n",
    "    print(\"- Ensure S3/MinIO configuration is correct\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nBasic queries completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analytical-queries-section",
   "metadata": {},
   "source": [
    "## Advanced Analytical Queries\n",
    "\n",
    "Demonstrate DuckDB's analytical capabilities with more complex queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "analytical-queries",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing advanced analytical queries...\n",
      "\n",
      "1. USER ACTIVITY SUMMARY:\n",
      "===================================\n",
      "   is_active  user_count  percentage\n",
      "0       True           4        80.0\n",
      "1      False           1        20.0\n",
      "\n",
      "2. USERNAME ANALYSIS:\n",
      "==============================\n",
      "        username  username_length length_category\n",
      "0  charlie_brown               13            Long\n",
      "1   alice_wonder               12            Long\n",
      "2    bob_builder               11          Medium\n",
      "3     jane_smith               10          Medium\n",
      "4       john_doe                8          Medium\n",
      "\n",
      "3. TEMPORAL ANALYSIS:\n",
      "============================\n",
      "   created_year  created_month  created_day  users_created  \\\n",
      "0          2025              7            1              5   \n",
      "\n",
      "             earliest_update              latest_update  \n",
      "0 2025-07-01 13:41:16.173663 2025-07-01 13:41:16.173663  \n",
      "\n",
      "4. USER RANKING BY EMAIL DOMAIN:\n",
      "========================================\n",
      "        username                      email       domain  is_active  user_rank\n",
      "0   alice_wonder   alice.wonder@example.com  example.com      False          1\n",
      "1    bob_builder    bob.builder@example.com  example.com       True          2\n",
      "2  charlie_brown  charlie.brown@example.com  example.com       True          3\n",
      "3     jane_smith     jane.smith@example.com  example.com       True          4\n",
      "4       john_doe       john.doe@example.com  example.com       True          5\n",
      "\n",
      "Advanced analytical queries completed\n"
     ]
    }
   ],
   "source": [
    "# Advanced analytical queries showcasing DuckDB's capabilities\n",
    "print(\"Executing advanced analytical queries...\")\n",
    "\n",
    "try:\n",
    "    # Query 1: Aggregation by activity status\n",
    "    print(\"\\n1. USER ACTIVITY SUMMARY:\")\n",
    "    print(\"=\" * 35)\n",
    "    activity_summary = conn.execute(f\"\"\"\n",
    "        SELECT \n",
    "            is_active,\n",
    "            COUNT(*) as user_count,\n",
    "            ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage\n",
    "        FROM {table_ref}\n",
    "        GROUP BY is_active\n",
    "        ORDER BY is_active DESC\n",
    "    \"\"\").fetchdf()\n",
    "    print(activity_summary)\n",
    "    \n",
    "    # Query 2: String analysis\n",
    "    print(\"\\n2. USERNAME ANALYSIS:\")\n",
    "    print(\"=\" * 30)\n",
    "    username_analysis = conn.execute(f\"\"\"\n",
    "        SELECT \n",
    "            username,\n",
    "            LENGTH(username) as username_length,\n",
    "            CASE \n",
    "                WHEN LENGTH(username) < 8 THEN 'Short'\n",
    "                WHEN LENGTH(username) < 12 THEN 'Medium'\n",
    "                ELSE 'Long'\n",
    "            END as length_category\n",
    "        FROM {table_ref}\n",
    "        ORDER BY LENGTH(username) DESC\n",
    "    \"\"\").fetchdf()\n",
    "    print(username_analysis)\n",
    "    \n",
    "    # Query 3: Date/time analysis\n",
    "    print(\"\\n3. TEMPORAL ANALYSIS:\")\n",
    "    print(\"=\" * 28)\n",
    "    temporal_analysis = conn.execute(f\"\"\"\n",
    "        SELECT \n",
    "            created_year,\n",
    "            created_month,\n",
    "            created_day,\n",
    "            COUNT(*) as users_created,\n",
    "            MIN(updated_at) as earliest_update,\n",
    "            MAX(updated_at) as latest_update\n",
    "        FROM {table_ref}\n",
    "        GROUP BY created_year, created_month, created_day\n",
    "        ORDER BY created_year, created_month, created_day\n",
    "    \"\"\").fetchdf()\n",
    "    print(temporal_analysis)\n",
    "    \n",
    "    # Query 4: Complex filtering and ranking\n",
    "    print(\"\\n4. USER RANKING BY EMAIL DOMAIN:\")\n",
    "    print(\"=\" * 40)\n",
    "    domain_analysis = conn.execute(f\"\"\"\n",
    "        SELECT \n",
    "            username,\n",
    "            email,\n",
    "            SPLIT_PART(email, '@', 2) as domain,\n",
    "            is_active,\n",
    "            ROW_NUMBER() OVER (ORDER BY username) as user_rank\n",
    "        FROM {table_ref}\n",
    "        WHERE email LIKE '%@example.com'\n",
    "        ORDER BY domain, username\n",
    "    \"\"\").fetchdf()\n",
    "    print(domain_analysis)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Advanced query execution failed: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nAdvanced analytical queries completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "performance-analysis-section",
   "metadata": {},
   "source": [
    "## Performance Analysis\n",
    "\n",
    "Analyze query performance and demonstrate DuckDB's optimization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "performance-analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing query performance...\n",
      "\n",
      "1. QUERY EXECUTION PLAN:\n",
      "===================================\n",
      "┌───────────────────────────┐\n",
      "│       HASH_GROUP_BY       │\n",
      "│    ────────────────────   │\n",
      "│         Groups: #0        │\n",
      "│                           │\n",
      "│        Aggregates:        │\n",
      "│        count_star()       │\n",
      "│                           │\n",
      "│          ~0 Rows          │\n",
      "└─────────────┬─────────────┘\n",
      "┌─────────────┴─────────────┐\n",
      "│         PROJECTION        │\n",
      "│    ────────────────────   │\n",
      "│         is_active         │\n",
      "│                           │\n",
      "│          ~1 Rows          │\n",
      "└─────────────┬─────────────┘\n",
      "┌─────────────┴─────────────┐\n",
      "│       ICEBERG_SCAN        │\n",
      "│    ────────────────────   │\n",
      "│         Function:         │\n",
      "│        ICEBERG_SCAN       │\n",
      "│                           │\n",
      "│        Projections:       │\n",
      "│         is_active         │\n",
      "│                           │\n",
      "│          Filters:         │\n",
      "│     created_year=2025     │\n",
      "│                           │\n",
      "│          ~1 Rows          │\n",
      "└───────────────────────────┘\n",
      "\n",
      "\n",
      "2. FILTERED AGGREGATION RESULT:\n",
      "========================================\n",
      "   is_active  user_count                                          usernames\n",
      "0       True           4  [john_doe, jane_smith, bob_builder, charlie_br...\n",
      "1      False           1                                     [alice_wonder]\n",
      "\n",
      "3. PARTITION PRUNING TEST:\n",
      "===================================\n",
      "Empty DataFrame\n",
      "Columns: [created_year, created_month, created_day, record_count]\n",
      "Index: []\n",
      "\n",
      "Performance Observations:\n",
      "- DuckDB uses vectorized execution for fast processing\n",
      "- Iceberg metadata enables partition pruning\n",
      "- Column-oriented storage optimizes analytical queries\n",
      "- Query planning leverages table statistics\n",
      "\n",
      "Performance analysis completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌─────────────────────────────────────┐\n",
      "│┌───────────────────────────────────┐│\n",
      "││    Query Profiling Information    ││\n",
      "│└───────────────────────────────────┘│\n",
      "└─────────────────────────────────────┘\n",
      "         SELECT              is_active,              COUNT(*) as user_count,             ARRAY_AGG(username) as usernames         FROM \"iceberg_catalog\".\"play_iceberg\".\"users\"          WHERE created_year = 2025          GROUP BY is_active         ORDER BY is_active DESC     \n",
      "┌─────────────────────────────────────┐\n",
      "│┌──────────────────────────��────────┐│\n",
      "││         HTTPFS HTTP Stats         ││\n",
      "││                                   ││\n",
      "││            in: 0 bytes            ││\n",
      "││            out: 0 bytes           ││\n",
      "││              #HEAD: 0             ││\n",
      "││              #GET: 0              ││\n",
      "││              #PUT: 0              ││\n",
      "││              #POST: 0             ││\n",
      "││             #DELETE: 0            ││\n",
      "│└───────────────────────────────────┘│\n",
      "└─────────────────────────────────────┘\n",
      "┌────────────────────────────────────────────────┐\n",
      "│┌──────────────────────────────────────────────┐��\n",
      "││              Total Time: 0.0392s             ││\n",
      "│└──────────────────────────────────────────────┘│\n",
      "└────────────────────────────────────────────────┘\n",
      "┌───────────────────────────┐\n",
      "│           QUERY           │\n",
      "└─────────────┬─────────────┘\n",
      "┌─────────────┴─────────────┐\n",
      "│          ORDER_BY         │\n",
      "│    ────────────────────   │\n",
      "│    users.is_active DESC   │\n",
      "│                           │\n",
      "│           2 Rows          │\n",
      "│          (0.00s)          │\n",
      "└─────────────┬─────────────┘\n",
      "┌─���───────────┴─────────────┐\n",
      "│       HASH_GROUP_BY       │\n",
      "│    ────────────────────   │\n",
      "│         Groups: #0        │\n",
      "│                           │\n",
      "│        Aggregates:        │\n",
      "│        count_star()       │\n",
      "│       array_agg(#1)       │\n",
      "│                           │\n",
      "│           2 Rows          │\n",
      "│          (0.00s)          │\n",
      "└─────────────┬─────────────┘\n",
      "┌─────────────┴─────────────┐\n",
      "│         PROJECTION        │\n",
      "│    ────────────────────   │\n",
      "│         is_active         │\n",
      "│          username         │\n",
      "│                           │\n",
      "│           5 Rows          │\n",
      "│          (0.00s)          │\n",
      "└─────────────┬─────────────���\n",
      "┌─────────────┴─────────────┐\n",
      "│         TABLE_SCAN        │\n",
      "│    ────────────────────   │\n",
      "│         Function:         │\n",
      "│        ICEBERG_SCAN       │\n",
      "│                           │\n",
      "│        Projections:       │\n",
      "│         is_active         │\n",
      "│          username         │\n",
      "│                           │\n",
      "│          Filters:         │\n",
      "│     created_year=2025     │\n",
      "│                           │\n",
      "│    Total Files Read: 1    │\n",
      "│                           │\n",
      "│           5 Rows          │\n",
      "│          (0.00s)          │\n",
      "└───────────────────────────┘\n",
      "\n",
      "\n",
      "\n",
      "┌─────────────────────────────────────┐\n",
      "│┌───────────────────────────────────┐│\n",
      "││    Query Profiling Information    ││\n",
      "│└───────────────────────────────────┘│\n",
      "└─────────────────────────────────────┘\n",
      "         SELECT              created_year,             created_month,             created_day,             COUNT(*) as record_count         FROM \"iceberg_catalog\".\"play_iceberg\".\"users\"         WHERE created_year = 2025            AND created_month = 6         GROUP BY created_year, created_month, created_day     \n",
      "┌─────────────────────────────────────┐\n",
      "│┌─────────────���─────────────────────┐│\n",
      "││         HTTPFS HTTP Stats         ││\n",
      "││                                   ││\n",
      "││            in: 0 bytes            ││\n",
      "││            out: 0 bytes           ││\n",
      "││              #HEAD: 0             ││\n",
      "││              #GET: 0              ││\n",
      "││              #PUT: 0              ││\n",
      "││              #POST: 0             ││\n",
      "││             #DELETE: 0            ││\n",
      "│└───────────────────────────────────┘│\n",
      "└─────────────────────────────────────┘\n",
      "┌────────────────────────────────────────────────┐\n",
      "│┌──────────────────────────────────���───────────┐│\n",
      "││              Total Time: 0.0233s             ││\n",
      "│└──────────────────────────────────────────────┘│\n",
      "└────────────────────────────────────────────────┘\n",
      "┌───────────────────────────┐\n",
      "│           QUERY           │\n",
      "└─────────────┬─────────────┘\n",
      "┌─────────────┴─────────────┐\n",
      "│       HASH_GROUP_BY       │\n",
      "│    ────────────────────   │\n",
      "│          Groups:          │\n",
      "│             #0            │\n",
      "│             #1            │\n",
      "│             #2            │\n",
      "│                           │\n",
      "│        Aggregates:        │\n",
      "│        count_star()       │\n",
      "│                           │\n",
      "│           0 Rows          │\n",
      "│          (0.00s)          │\n",
      "└─────────────┬─────────────┘\n",
      "┌─────────────┴─────────────┐\n",
      "│         PROJECTION        │\n",
      "│    ────────────────────   │\n",
      "│        created_year       │\n",
      "│       created_month       │\n",
      "│        created_day        │\n",
      "│                           │\n",
      "│           0 Rows          │\n",
      "│          (0.00s)          │\n",
      "└─────────────┬─────────────┘\n",
      "┌─────────────┴─────────────┐\n",
      "│         TABLE_SCAN        │\n",
      "│    ────────────────────   │\n",
      "│         Function:         │\n",
      "│        ICEBERG_SCAN       │\n",
      "│                           │\n",
      "│        Projections:       │\n",
      "│        created_year       │\n",
      "│       created_month       │\n",
      "│        created_day        │\n",
      "│                           │\n",
      "│          Filters:         │\n",
      "│     created_year=2025     │\n",
      "│      created_month=6      │\n",
      "│                           │\n",
      "│    Total Files Read: 0    │\n",
      "│                           │\n",
      "│           0 Rows          │\n",
      "│          (0.00s)          │\n",
      "└───────────────────────────┘\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performance analysis and optimization demonstration\n",
    "print(\"Analyzing query performance...\")\n",
    "\n",
    "try:\n",
    "    # Enable query profiling\n",
    "    conn.execute(\"PRAGMA enable_profiling\")\n",
    "    \n",
    "    # Query with EXPLAIN for optimization analysis\n",
    "    print(\"\\n1. QUERY EXECUTION PLAN:\")\n",
    "    print(\"=\" * 35)\n",
    "    explain_result = conn.execute(f\"\"\"\n",
    "        EXPLAIN SELECT \n",
    "            is_active, \n",
    "            COUNT(*) as user_count \n",
    "        FROM {table_ref} \n",
    "        WHERE created_year = 2025 \n",
    "        GROUP BY is_active\n",
    "    \"\"\").fetchall()\n",
    "    \n",
    "    for row in explain_result:\n",
    "        print(row[1])  # Print the explain plan\n",
    "    \n",
    "    # Execute the actual query\n",
    "    print(\"\\n2. FILTERED AGGREGATION RESULT:\")\n",
    "    print(\"=\" * 40)\n",
    "    filtered_result = conn.execute(f\"\"\"\n",
    "        SELECT \n",
    "            is_active, \n",
    "            COUNT(*) as user_count,\n",
    "            ARRAY_AGG(username) as usernames\n",
    "        FROM {table_ref} \n",
    "        WHERE created_year = 2025 \n",
    "        GROUP BY is_active\n",
    "        ORDER BY is_active DESC\n",
    "    \"\"\").fetchdf()\n",
    "    print(filtered_result)\n",
    "    \n",
    "    # Test partition pruning (if applicable)\n",
    "    print(\"\\n3. PARTITION PRUNING TEST:\")\n",
    "    print(\"=\" * 35)\n",
    "    partition_query = conn.execute(f\"\"\"\n",
    "        SELECT \n",
    "            created_year,\n",
    "            created_month,\n",
    "            created_day,\n",
    "            COUNT(*) as record_count\n",
    "        FROM {table_ref}\n",
    "        WHERE created_year = 2025 \n",
    "          AND created_month = 6\n",
    "        GROUP BY created_year, created_month, created_day\n",
    "    \"\"\").fetchdf()\n",
    "    print(partition_query)\n",
    "    \n",
    "    print(\"\\nPerformance Observations:\")\n",
    "    print(\"- DuckDB uses vectorized execution for fast processing\")\n",
    "    print(\"- Iceberg metadata enables partition pruning\")\n",
    "    print(\"- Column-oriented storage optimizes analytical queries\")\n",
    "    print(\"- Query planning leverages table statistics\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Performance analysis failed: {e}\")\n",
    "    \n",
    "print(\"\\nPerformance analysis completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-section",
   "metadata": {},
   "source": [
    "## Comparison: DuckDB vs PyIceberg\n",
    "\n",
    "Compare query results between DuckDB and PyIceberg to verify consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing DuckDB vs PyIceberg query results...\n",
      "\n",
      "1. DUCKDB RESULTS:\n",
      "=========================\n",
      "   total_count  active_count  avg_username_length\n",
      "0            5           4.0                 10.8\n",
      "\n",
      "2. PYICEBERG RESULTS:\n",
      "===========================\n",
      "   total_count  active_count  avg_username_length\n",
      "0            5             4                 10.8\n",
      "\n",
      "3. CONSISTENCY CHECK:\n",
      "===========================\n",
      "  ✓ Total Count: DuckDB=5, PyIceberg=5\n",
      "  ✓ Active Count: DuckDB=4.0, PyIceberg=4\n",
      "  ✓ Avg Username Length: DuckDB=10.8, PyIceberg=10.8\n",
      "\n",
      "✅ All results are consistent between DuckDB and PyIceberg\n",
      "\n",
      "Comparison analysis completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌─────────────────────────────────────┐\n",
      "│┌───────────────────────────────────┐│\n",
      "││    Query Profiling Information    ││\n",
      "│└───────────────────────────────────┘│\n",
      "└─────────────────────────────────────┘\n",
      "         SELECT              COUNT(*) as total_count,             SUM(CASE WHEN is_active THEN 1 ELSE 0 END) as active_count,             AVG(LENGTH(username)) as avg_username_length         FROM \"iceberg_catalog\".\"play_iceberg\".\"users\"     \n",
      "┌─────────────────────────────────────┐\n",
      "│┌───────────────────────────────────┐│\n",
      "��│         HTTPFS HTTP Stats         ││\n",
      "││                                   ││\n",
      "││            in: 0 bytes            ││\n",
      "││            out: 0 bytes           ││\n",
      "││              #HEAD: 0             ││\n",
      "││              #GET: 0              ││\n",
      "││              #PUT: 0              ││\n",
      "││              #POST: 0             ││\n",
      "││             #DELETE: 0            ││\n",
      "│└───────────────────────────────────┘│\n",
      "└─────────────────────────────────────┘\n",
      "┌────────────────────────────────────────────────┐\n",
      "│┌──────────────────────────────────────────────┐│\n",
      "││              Total Time: 0.0265s             ││\n",
      "│└──────────────────────────────────────────────┘│\n",
      "└────────────────────────────────────────────────┘\n",
      "┌───────────────────────────┐\n",
      "│           QUERY           │\n",
      "└─────────────┬─────────────┘\n",
      "┌─────────────┴─────────────┐\n",
      "│    UNGROUPED_AGGREGATE    │\n",
      "│    ────────────────────   │\n",
      "│        Aggregates:        │\n",
      "│        count_star()       │\n",
      "│    sum_no_overflow(#0)    │\n",
      "│          avg(#1)          │\n",
      "│                           │\n",
      "│           1 Rows          │\n",
      "│          (0.00s)          │\n",
      "└─────────────┬─────────────┘\n",
      "┌─────────────┴─────────────┐\n",
      "│         PROJECTION        │\n",
      "│    ────────────────────   │\n",
      "│   CASE  WHEN (is_active)  │\n",
      "│     THEN (1) ELSE 0 END   │\n",
      "│      length(username)     │\n",
      "│                           │\n",
      "│           5 Rows          │\n",
      "│          (0.00s)          │\n",
      "└─────────────┬─────────────┘\n",
      "┌─────────────┴─────────────┐\n",
      "│         TABLE_SCAN        │\n",
      "│    ────────────────────   │\n",
      "│         Function:         │\n",
      "│        ICEBERG_SCAN       │\n",
      "│                           │\n",
      "│        Projections:       │\n",
      "│         is_active         │\n",
      "│          username         │\n",
      "│                           │\n",
      "│    Total Files Read: 1    │\n",
      "│                           │\n",
      "│           5 Rows          │\n",
      "│          (0.00s)          │\n",
      "└───────────────────────────┘\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare results between DuckDB and PyIceberg\n",
    "print(\"Comparing DuckDB vs PyIceberg query results...\")\n",
    "\n",
    "try:\n",
    "    # DuckDB query\n",
    "    print(\"\\n1. DUCKDB RESULTS:\")\n",
    "    print(\"=\" * 25)\n",
    "    duckdb_result = conn.execute(f\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_count,\n",
    "            SUM(CASE WHEN is_active THEN 1 ELSE 0 END) as active_count,\n",
    "            AVG(LENGTH(username)) as avg_username_length\n",
    "        FROM {table_ref}\n",
    "    \"\"\").fetchdf()\n",
    "    print(duckdb_result)\n",
    "    \n",
    "    # PyIceberg equivalent\n",
    "    print(\"\\n2. PYICEBERG RESULTS:\")\n",
    "    print(\"=\" * 27)\n",
    "    pyiceberg_data = users_table.scan().to_pandas()\n",
    "    \n",
    "    pyiceberg_summary = {\n",
    "        'total_count': len(pyiceberg_data),\n",
    "        'active_count': pyiceberg_data['is_active'].sum(),\n",
    "        'avg_username_length': pyiceberg_data['username'].str.len().mean()\n",
    "    }\n",
    "    \n",
    "    pyiceberg_df = pd.DataFrame([pyiceberg_summary])\n",
    "    print(pyiceberg_df)\n",
    "    \n",
    "    # Verification\n",
    "    print(\"\\n3. CONSISTENCY CHECK:\")\n",
    "    print(\"=\" * 27)\n",
    "    \n",
    "    consistency_checks = [\n",
    "        ('Total Count', \n",
    "         duckdb_result['total_count'].iloc[0], \n",
    "         pyiceberg_summary['total_count']),\n",
    "        ('Active Count', \n",
    "         duckdb_result['active_count'].iloc[0], \n",
    "         pyiceberg_summary['active_count']),\n",
    "        ('Avg Username Length', \n",
    "         round(duckdb_result['avg_username_length'].iloc[0], 2), \n",
    "         round(pyiceberg_summary['avg_username_length'], 2))\n",
    "    ]\n",
    "    \n",
    "    all_consistent = True\n",
    "    for metric, duckdb_val, pyiceberg_val in consistency_checks:\n",
    "        is_consistent = duckdb_val == pyiceberg_val\n",
    "        all_consistent = all_consistent and is_consistent\n",
    "        status = \"✓\" if is_consistent else \"✗\"\n",
    "        print(f\"  {status} {metric}: DuckDB={duckdb_val}, PyIceberg={pyiceberg_val}\")\n",
    "    \n",
    "    if all_consistent:\n",
    "        print(\"\\n✅ All results are consistent between DuckDB and PyIceberg\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ Some inconsistencies found - investigate further\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Comparison failed: {e}\")\n",
    "\n",
    "print(\"\\nComparison analysis completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best-practices-section",
   "metadata": {},
   "source": [
    "## Best Practices and Optimization Tips\n",
    "\n",
    "Guidelines for effective DuckDB-Iceberg integration in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "best-practices",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB-Iceberg Best Practices:\n",
      "========================================\n",
      "\n",
      "1. QUERY OPTIMIZATION:\n",
      "   - Use column projection to reduce data transfer\n",
      "   - Apply filters early to leverage partition pruning\n",
      "   - Utilize DuckDB's vectorized execution\n",
      "   - Consider query result caching for repeated analyses\n",
      "\n",
      "2. CONNECTION MANAGEMENT:\n",
      "   - Reuse connections for multiple queries\n",
      "   - Configure appropriate timeouts\n",
      "   - Handle connection failures gracefully\n",
      "   - Monitor connection pool usage\n",
      "\n",
      "3. PERFORMANCE OPTIMIZATION:\n",
      "   - Enable query profiling for performance analysis\n",
      "   - Use EXPLAIN to understand query plans\n",
      "   - Leverage Iceberg's metadata for efficient scanning\n",
      "   - Consider data locality and network bandwidth\n",
      "\n",
      "4. ERROR HANDLING:\n",
      "   - Implement retry logic for transient failures\n",
      "   - Validate table accessibility before queries\n",
      "   - Handle schema evolution gracefully\n",
      "   - Log query performance metrics\n",
      "\n",
      "5. OPTIMIZATION EXAMPLE:\n",
      "==============================\n",
      "Optimized query returned 4 results\n",
      "        username                      email\n",
      "0    bob_builder    bob.builder@example.com\n",
      "1  charlie_brown  charlie.brown@example.com\n",
      "2     jane_smith     jane.smith@example.com\n",
      "3       john_doe       john.doe@example.com\n",
      "\n",
      "Optimization features used:\n",
      "  ✓ Column projection (username, email only)\n",
      "  ✓ Early filtering (is_active, created_year)\n",
      "  ✓ Result limiting (LIMIT 10)\n",
      "  ✓ Sorted output (ORDER BY username)\n",
      "\n",
      "Best practices demonstration completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌─────────────────────────────────────┐\n",
      "│┌───────────────────────────────────┐│\n",
      "││    Query Profiling Information    ││\n",
      "│└───────────────────────────────────┘│\n",
      "└─────────────────────────────────────┘\n",
      "         SELECT username, email          FROM \"iceberg_catalog\".\"play_iceberg\".\"users\"         WHERE is_active = true            AND created_year = 2025         ORDER BY username         LIMIT 10     \n",
      "┌─────────────────────────────────────┐\n",
      "│┌───────────────────────────────────┐│\n",
      "││         HTTPFS HTTP Stats         ��│\n",
      "││                                   ││\n",
      "││            in: 0 bytes            ││\n",
      "││            out: 0 bytes           ││\n",
      "││              #HEAD: 0             ││\n",
      "││              #GET: 0              ││\n",
      "││              #PUT: 0              ││\n",
      "││              #POST: 0             ││\n",
      "││             #DELETE: 0            ││\n",
      "│└───────────────────────────────────┘│\n",
      "└─────────────────────────────────────┘\n",
      "┌────────────────────────────────────────────────┐\n",
      "│┌──────────────────────────────────────────────┐│\n",
      "││              Total Time: 0.0303s             ││\n",
      "│└──��───────────────────────────────────────────┘│\n",
      "└────────────────────────────────────────────────┘\n",
      "┌───────────────────────────┐\n",
      "│           QUERY           │\n",
      "└─────────────┬─────────────┘\n",
      "┌─────────────┴─────────────┐\n",
      "│           TOP_N           │\n",
      "│    ────────────────────   │\n",
      "│          Top: 10          │\n",
      "│                           │\n",
      "│         Order By:         │\n",
      "│     users.username ASC    │\n",
      "│                           │\n",
      "│           4 Rows          │\n",
      "│          (0.00s)          │\n",
      "└─────────────┬───────��─────┘\n",
      "┌─────────────┴─────────────┐\n",
      "│         TABLE_SCAN        │\n",
      "│    ────────────────────   │\n",
      "│         Function:         │\n",
      "│        ICEBERG_SCAN       │\n",
      "│                           │\n",
      "│        Projections:       │\n",
      "│          username         │\n",
      "│           email           │\n",
      "│                           │\n",
      "│          Filters:         │\n",
      "│       is_active=true      │\n",
      "│     created_year=2025     │\n",
      "│ optional: Dynamic Filter  │\n",
      "│         (username)        │\n",
      "│                           │\n",
      "│    Total Files Read: 1    │\n",
      "│                           │\n",
      "│           4 Rows          │\n",
      "│          (0.00s)          │\n",
      "└───────────────────────────┘\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate best practices for DuckDB-Iceberg integration\n",
    "print(\"DuckDB-Iceberg Best Practices:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"\\n1. QUERY OPTIMIZATION:\")\n",
    "print(\"   - Use column projection to reduce data transfer\")\n",
    "print(\"   - Apply filters early to leverage partition pruning\")\n",
    "print(\"   - Utilize DuckDB's vectorized execution\")\n",
    "print(\"   - Consider query result caching for repeated analyses\")\n",
    "\n",
    "print(\"\\n2. CONNECTION MANAGEMENT:\")\n",
    "print(\"   - Reuse connections for multiple queries\")\n",
    "print(\"   - Configure appropriate timeouts\")\n",
    "print(\"   - Handle connection failures gracefully\")\n",
    "print(\"   - Monitor connection pool usage\")\n",
    "\n",
    "print(\"\\n3. PERFORMANCE OPTIMIZATION:\")\n",
    "print(\"   - Enable query profiling for performance analysis\")\n",
    "print(\"   - Use EXPLAIN to understand query plans\")\n",
    "print(\"   - Leverage Iceberg's metadata for efficient scanning\")\n",
    "print(\"   - Consider data locality and network bandwidth\")\n",
    "\n",
    "print(\"\\n4. ERROR HANDLING:\")\n",
    "print(\"   - Implement retry logic for transient failures\")\n",
    "print(\"   - Validate table accessibility before queries\")\n",
    "print(\"   - Handle schema evolution gracefully\")\n",
    "print(\"   - Log query performance metrics\")\n",
    "\n",
    "# Demonstrate query optimization example\n",
    "print(\"\\n5. OPTIMIZATION EXAMPLE:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "try:\n",
    "    # Optimized query with early filtering and column projection\n",
    "    optimized_query = f\"\"\"\n",
    "        SELECT username, email \n",
    "        FROM {table_ref}\n",
    "        WHERE is_active = true \n",
    "          AND created_year = 2025\n",
    "        ORDER BY username\n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    "    \n",
    "    optimized_result = conn.execute(optimized_query).fetchdf()\n",
    "    print(f\"Optimized query returned {len(optimized_result)} results\")\n",
    "    print(optimized_result)\n",
    "    \n",
    "    print(\"\\nOptimization features used:\")\n",
    "    print(\"  ✓ Column projection (username, email only)\")\n",
    "    print(\"  ✓ Early filtering (is_active, created_year)\")\n",
    "    print(\"  ✓ Result limiting (LIMIT 10)\")\n",
    "    print(\"  ✓ Sorted output (ORDER BY username)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Optimization example failed: {e}\")\n",
    "\n",
    "print(\"\\nBest practices demonstration completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-section",
   "metadata": {},
   "source": [
    "## Cleanup and Session Management\n",
    "\n",
    "Properly close connections and clean up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cleanup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up connections and resources...\n",
      "✓ DuckDB connection closed\n",
      "✓ Cleanup completed successfully\n",
      "\n",
      "Session ended - resources released\n"
     ]
    }
   ],
   "source": [
    "# Clean up connections and resources\n",
    "print(\"Cleaning up connections and resources...\")\n",
    "\n",
    "try:\n",
    "    # Close DuckDB connection\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "        print(\"✓ DuckDB connection closed\")\n",
    "    \n",
    "    print(\"✓ Cleanup completed successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Cleanup error: {e}\")\n",
    "\n",
    "print(\"\\nSession ended - resources released\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated comprehensive querying of Apache Iceberg tables using DuckDB:\n",
    "\n",
    "### What We Accomplished:\n",
    "1. **Environment Setup**: Configured DuckDB with Iceberg extension\n",
    "2. **Catalog Integration**: Connected DuckDB to Iceberg REST catalog\n",
    "3. **Basic Querying**: Executed fundamental SQL operations\n",
    "4. **Advanced Analytics**: Demonstrated complex analytical queries\n",
    "5. **Performance Analysis**: Explored query optimization techniques\n",
    "6. **Result Verification**: Compared DuckDB and PyIceberg outputs\n",
    "\n",
    "### Key Benefits Demonstrated:\n",
    "- **SQL Interface**: Standard SQL for familiar querying\n",
    "- **High Performance**: Vectorized execution engine\n",
    "- **Native Integration**: Built-in Iceberg support\n",
    "- **Analytical Focus**: Optimized for complex analytics\n",
    "- **Lightweight**: No server infrastructure required\n",
    "\n",
    "### Technical Concepts Learned:\n",
    "- **Catalog Configuration**: How to connect DuckDB to Iceberg catalogs\n",
    "- **Query Optimization**: Leveraging partition pruning and column projection\n",
    "- **Performance Analysis**: Using EXPLAIN and profiling tools\n",
    "- **Error Handling**: Robust connection and query management\n",
    "\n",
    "### Use Cases for DuckDB-Iceberg:\n",
    "1. **Interactive Analysis**: Ad-hoc data exploration\n",
    "2. **Reporting**: Analytical reports and dashboards\n",
    "3. **Data Science**: Exploratory data analysis\n",
    "4. **ETL Validation**: Data quality checks and validation\n",
    "5. **Performance Testing**: Query performance analysis\n",
    "\n",
    "DuckDB provides an excellent SQL interface for Iceberg tables, combining the flexibility of SQL with the performance benefits of columnar analytics engines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
