{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Creating an Apache Iceberg Table\n",
    "\n",
    "This notebook demonstrates how to create a user table in Apache Iceberg using the Python API (PyIceberg). We'll explore table creation, schema definition, and partitioning strategies.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you'll understand:\n",
    "- How to connect to an Iceberg REST catalog\n",
    "- How to define table schemas with proper data types\n",
    "- How to implement effective partitioning strategies\n",
    "- How to create namespaces for table organization\n",
    "- Best practices for table design\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Docker environment running (MinIO, Iceberg REST catalog)\n",
    "- PyIceberg library installed\n",
    "- Basic understanding of data types and partitioning\n",
    "\n",
    "## Table Design Overview\n",
    "\n",
    "We'll create a `users` table with the following characteristics:\n",
    "- **Schema**: User profile information with timestamps\n",
    "- **Partitioning**: By date (year/month/day) for efficient querying\n",
    "- **Storage**: Parquet format with columnar optimization\n",
    "- **Evolution**: Schema designed for future extensibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, let's import the necessary PyIceberg libraries and set up our connection to the REST catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyIceberg libraries imported successfully\n",
      "Ready to create Iceberg table\n"
     ]
    }
   ],
   "source": [
    "from pyiceberg.catalog import load_catalog\n",
    "from pyiceberg.schema import Schema\n",
    "from pyiceberg.types import (\n",
    "    NestedField,\n",
    "    StringType,\n",
    "    LongType,\n",
    "    BooleanType,\n",
    "    TimestampType,\n",
    "    IntegerType\n",
    ")\n",
    "from pyiceberg.partitioning import PartitionSpec, PartitionField\n",
    "from pyiceberg.transforms import IdentityTransform\n",
    "from pyiceberg.exceptions import TableAlreadyExistsError, NamespaceAlreadyExistsError\n",
    "\n",
    "print(\"PyIceberg libraries imported successfully\")\n",
    "print(\"Ready to create Iceberg table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catalog-connection-section",
   "metadata": {},
   "source": [
    "## Catalog Connection\n",
    "\n",
    "Connect to the Iceberg REST catalog. The catalog serves as the entry point for all table operations and maintains the mapping between table names and their metadata locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "catalog-connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog connected successfully!\n",
      "Existing namespaces: []\n"
     ]
    }
   ],
   "source": [
    "# Configure the REST catalog with MinIO backend\n",
    "catalog_config = {\n",
    "    \"uri\": \"http://localhost:8181\",\n",
    "    \"s3.endpoint\": \"http://localhost:9000\",\n",
    "    \"s3.access-key-id\": \"admin\",\n",
    "    \"s3.secret-access-key\": \"password\",\n",
    "    \"s3.path-style-access\": \"true\",\n",
    "}\n",
    "\n",
    "# Load the catalog\n",
    "try:\n",
    "    catalog = load_catalog(\"rest\", **catalog_config)\n",
    "    print(\"Catalog connected successfully!\")\n",
    "    \n",
    "    # List existing namespaces\n",
    "    namespaces = list(catalog.list_namespaces())\n",
    "    print(f\"Existing namespaces: {namespaces}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to catalog: {e}\")\n",
    "    print(\"Please ensure Docker services are running\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "namespace-section",
   "metadata": {},
   "source": [
    "## Namespace Creation\n",
    "\n",
    "Namespaces in Iceberg are logical containers for organizing tables, similar to databases in traditional systems. They help organize tables and provide access control boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "namespace-creation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating namespace: play-iceberg\n",
      "Namespaces provide logical organization for tables\n",
      "They support hierarchical organization and access control\n",
      "Namespace 'play-iceberg' created successfully!\n",
      "Current namespaces: [('play-iceberg',)]\n"
     ]
    }
   ],
   "source": [
    "# Define namespace for our user management system\n",
    "namespace = \"play-iceberg\"\n",
    "\n",
    "print(f\"Creating namespace: {namespace}\")\n",
    "print(\"Namespaces provide logical organization for tables\")\n",
    "print(\"They support hierarchical organization and access control\")\n",
    "\n",
    "try:\n",
    "    catalog.create_namespace(namespace)\n",
    "    print(f\"Namespace '{namespace}' created successfully!\")\n",
    "except NamespaceAlreadyExistsError:\n",
    "    print(f\"Namespace '{namespace}' already exists - continuing\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating namespace: {e}\")\n",
    "    \n",
    "# Verify namespace creation\n",
    "updated_namespaces = list(catalog.list_namespaces())\n",
    "print(f\"Current namespaces: {updated_namespaces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "schema-design-section",
   "metadata": {},
   "source": [
    "## Schema Design\n",
    "\n",
    "Define the table schema with careful consideration of:\n",
    "- **Data Types**: Choose appropriate types for storage efficiency\n",
    "- **Field IDs**: Unique identifiers that support schema evolution\n",
    "- **Nullability**: Required vs optional fields\n",
    "- **Future Evolution**: Design for extensibility\n",
    "\n",
    "### Schema Design Principles:\n",
    "1. **Stable Field IDs**: Never reuse field IDs for schema evolution\n",
    "2. **Descriptive Names**: Clear, consistent naming conventions\n",
    "3. **Appropriate Types**: Match data types to usage patterns\n",
    "4. **Partition-Friendly**: Include fields suitable for partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "schema-definition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining user table schema...\n",
      "\n",
      "Schema Design Considerations:\n",
      "- user_id: Primary key, long type for large scale\n",
      "- username/email: String types for text data\n",
      "- is_active: Boolean for efficient filtering\n",
      "- created_*: Integer fields for partition keys\n",
      "- updated_at: Timestamp for audit trails\n",
      "\n",
      "Schema defined with 8 fields\n",
      "Field IDs assigned: 1-8 (leaving gaps for future evolution)\n"
     ]
    }
   ],
   "source": [
    "# Define the schema for the User table\n",
    "print(\"Defining user table schema...\")\n",
    "print(\"\\nSchema Design Considerations:\")\n",
    "print(\"- user_id: Primary key, long type for large scale\")\n",
    "print(\"- username/email: String types for text data\")\n",
    "print(\"- is_active: Boolean for efficient filtering\")\n",
    "print(\"- created_*: Integer fields for partition keys\")\n",
    "print(\"- updated_at: Timestamp for audit trails\")\n",
    "\n",
    "user_schema = Schema(\n",
    "    # Primary identifier\n",
    "    NestedField(\n",
    "        field_id=1, \n",
    "        name=\"user_id\", \n",
    "        field_type=LongType(), \n",
    "        required=True\n",
    "    ),\n",
    "    \n",
    "    # User profile information\n",
    "    NestedField(\n",
    "        field_id=2, \n",
    "        name=\"username\", \n",
    "        field_type=StringType(), \n",
    "        required=True\n",
    "    ),\n",
    "    NestedField(\n",
    "        field_id=3, \n",
    "        name=\"email\", \n",
    "        field_type=StringType(), \n",
    "        required=True\n",
    "    ),\n",
    "    NestedField(\n",
    "        field_id=4, \n",
    "        name=\"is_active\", \n",
    "        field_type=BooleanType(), \n",
    "        required=True\n",
    "    ),\n",
    "    \n",
    "    # Partition key fields (created date components)\n",
    "    NestedField(\n",
    "        field_id=5, \n",
    "        name=\"created_year\", \n",
    "        field_type=IntegerType(), \n",
    "        required=True\n",
    "    ),\n",
    "    NestedField(\n",
    "        field_id=6, \n",
    "        name=\"created_month\", \n",
    "        field_type=IntegerType(), \n",
    "        required=True\n",
    "    ),\n",
    "    NestedField(\n",
    "        field_id=7, \n",
    "        name=\"created_day\", \n",
    "        field_type=IntegerType(), \n",
    "        required=True\n",
    "    ),\n",
    "    \n",
    "    # Audit timestamp\n",
    "    NestedField(\n",
    "        field_id=8, \n",
    "        name=\"updated_at\", \n",
    "        field_type=TimestampType(), \n",
    "        required=True\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"\\nSchema defined with {len(user_schema.fields)} fields\")\n",
    "print(\"Field IDs assigned: 1-8 (leaving gaps for future evolution)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partitioning-section",
   "metadata": {},
   "source": [
    "## Partitioning Strategy\n",
    "\n",
    "Partitioning is crucial for query performance and data management. We'll partition by date components to:\n",
    "- **Enable Partition Pruning**: Skip irrelevant partitions during queries\n",
    "- **Improve Data Locality**: Group related data together\n",
    "- **Support Data Lifecycle**: Easy deletion of old data\n",
    "- **Optimize Storage**: Better compression within partitions\n",
    "\n",
    "### Partitioning Best Practices:\n",
    "1. **Align with Query Patterns**: Partition by frequently filtered columns\n",
    "2. **Avoid Over-Partitioning**: Too many small partitions hurt performance\n",
    "3. **Consider Data Distribution**: Ensure relatively even partition sizes\n",
    "4. **Plan for Growth**: Partition strategy should scale with data volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "partition-definition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining partitioning strategy...\n",
      "\n",
      "Partitioning by date (year/month/day):\n",
      "- Enables efficient time-range queries\n",
      "- Supports data retention policies\n",
      "- Improves query performance through partition pruning\n",
      "- Facilitates data lifecycle management\n",
      "\n",
      "Partition specification created:\n",
      "- 3 partition fields (year, month, day)\n",
      "- Identity transform (no data transformation)\n",
      "- Field IDs: 1000-1002 (reserved for partition fields)\n",
      "\n",
      "Expected partition structure:\n",
      "created_year=2025/created_month=6/created_day=27/\n",
      "This creates a hierarchical directory structure\n"
     ]
    }
   ],
   "source": [
    "# Define partitioning strategy\n",
    "print(\"Defining partitioning strategy...\")\n",
    "print(\"\\nPartitioning by date (year/month/day):\")\n",
    "print(\"- Enables efficient time-range queries\")\n",
    "print(\"- Supports data retention policies\")\n",
    "print(\"- Improves query performance through partition pruning\")\n",
    "print(\"- Facilitates data lifecycle management\")\n",
    "\n",
    "# Create partition specification\n",
    "# Partition by year, month, and day for fine-grained control\n",
    "partition_spec = PartitionSpec(\n",
    "    PartitionField(\n",
    "        source_id=5,  # created_year field\n",
    "        field_id=1000, \n",
    "        transform=IdentityTransform(), \n",
    "        name=\"created_year\"\n",
    "    ),\n",
    "    PartitionField(\n",
    "        source_id=6,  # created_month field\n",
    "        field_id=1001, \n",
    "        transform=IdentityTransform(), \n",
    "        name=\"created_month\"\n",
    "    ),\n",
    "    PartitionField(\n",
    "        source_id=7,  # created_day field\n",
    "        field_id=1002, \n",
    "        transform=IdentityTransform(), \n",
    "        name=\"created_day\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"\\nPartition specification created:\")\n",
    "print(\"- 3 partition fields (year, month, day)\")\n",
    "print(\"- Identity transform (no data transformation)\")\n",
    "print(\"- Field IDs: 1000-1002 (reserved for partition fields)\")\n",
    "\n",
    "print(\"\\nExpected partition structure:\")\n",
    "print(\"created_year=2025/created_month=6/created_day=27/\")\n",
    "print(\"This creates a hierarchical directory structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "table-creation-section",
   "metadata": {},
   "source": [
    "## Table Creation\n",
    "\n",
    "Now we'll create the table with our defined schema and partitioning strategy. Iceberg table creation is atomic - either the entire table is created successfully or the operation fails with no side effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "table-creation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table: play-iceberg.users\n",
      "\n",
      "Table creation process:\n",
      "1. Validate schema and partition specification\n",
      "2. Create metadata files in object storage\n",
      "3. Register table in catalog\n",
      "4. Return table reference for operations\n",
      "\n",
      "Table 'play-iceberg.users' created successfully!\n",
      "Table is ready for data operations\n",
      "\n",
      "Table reference obtained: Table\n"
     ]
    }
   ],
   "source": [
    "# Create the User table\n",
    "table_name = f\"{namespace}.users\"\n",
    "\n",
    "print(f\"Creating table: {table_name}\")\n",
    "print(\"\\nTable creation process:\")\n",
    "print(\"1. Validate schema and partition specification\")\n",
    "print(\"2. Create metadata files in object storage\")\n",
    "print(\"3. Register table in catalog\")\n",
    "print(\"4. Return table reference for operations\")\n",
    "\n",
    "try:\n",
    "    user_table = catalog.create_table(\n",
    "        table_name, \n",
    "        schema=user_schema, \n",
    "        partition_spec=partition_spec\n",
    "    )\n",
    "    print(f\"\\nTable '{table_name}' created successfully!\")\n",
    "    print(\"Table is ready for data operations\")\n",
    "    \n",
    "except TableAlreadyExistsError:\n",
    "    print(f\"\\nTable '{table_name}' already exists\")\n",
    "    print(\"Loading existing table reference...\")\n",
    "    user_table = catalog.load_table(table_name)\n",
    "    print(\"Existing table loaded successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nError creating table: {e}\")\n",
    "    raise\n",
    "\n",
    "print(f\"\\nTable reference obtained: {type(user_table).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "table-inspection-section",
   "metadata": {},
   "source": [
    "## Table Inspection\n",
    "\n",
    "Let's examine the created table to understand its structure and properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "table-inspection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Inspection:\n",
      "========================================\n",
      "\n",
      "Table Schema:\n",
      "table {\n",
      "  1: user_id: required long\n",
      "  2: username: required string\n",
      "  3: email: required string\n",
      "  4: is_active: required boolean\n",
      "  5: created_year: required int\n",
      "  6: created_month: required int\n",
      "  7: created_day: required int\n",
      "  8: updated_at: required timestamp\n",
      "}\n",
      "\n",
      "Partition Specification:\n",
      "[\n",
      "  1000: created_year: identity(5)\n",
      "  1001: created_month: identity(6)\n",
      "  1002: created_day: identity(7)\n",
      "]\n",
      "\n",
      "Table Properties:\n",
      "  write.parquet.compression-codec: zstd\n",
      "\n",
      "Current Snapshot:\n",
      "  No data snapshots (empty table)\n",
      "\n",
      "Table Status: Ready for data operations\n"
     ]
    }
   ],
   "source": [
    "# Inspect the created table\n",
    "print(\"Table Inspection:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Display table schema\n",
    "print(\"\\nTable Schema:\")\n",
    "print(user_table.schema())\n",
    "\n",
    "# Display partition specification\n",
    "print(\"\\nPartition Specification:\")\n",
    "print(user_table.spec())\n",
    "\n",
    "# Table properties\n",
    "print(\"\\nTable Properties:\")\n",
    "properties = user_table.properties\n",
    "if properties:\n",
    "    for key, value in properties.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"  No custom properties set\")\n",
    "\n",
    "# Current snapshot information\n",
    "print(\"\\nCurrent Snapshot:\")\n",
    "current_snapshot = user_table.current_snapshot()\n",
    "if current_snapshot:\n",
    "    print(f\"  Snapshot ID: {current_snapshot.snapshot_id}\")\n",
    "    print(f\"  Timestamp: {current_snapshot.timestamp_ms}\")\n",
    "else:\n",
    "    print(\"  No data snapshots (empty table)\")\n",
    "\n",
    "print(\"\\nTable Status: Ready for data operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verification-section",
   "metadata": {},
   "source": [
    "## Table Verification\n",
    "\n",
    "Verify the table was created correctly by checking catalog listings and table accessibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "table-verification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Verification:\n",
      "==============================\n",
      "\n",
      "Tables in 'play-iceberg' namespace:\n",
      "  - ('play-iceberg', 'users')\n",
      "\n",
      "Table accessibility test: SUCCESS\n",
      "Table can be loaded and accessed\n",
      "\n",
      "Table Creation Summary:\n",
      "- Namespace: play-iceberg\n",
      "- Table: users\n",
      "- Full name: play-iceberg.users\n",
      "- Schema fields: 8\n",
      "- Partition fields: 3\n",
      "- Status: Ready for data operations\n"
     ]
    }
   ],
   "source": [
    "# Verify table creation\n",
    "print(\"Table Verification:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# List tables in namespace\n",
    "try:\n",
    "    tables_in_namespace = list(catalog.list_tables(namespace))\n",
    "    print(f\"\\nTables in '{namespace}' namespace:\")\n",
    "    for table_id in tables_in_namespace:\n",
    "        print(f\"  - {table_id}\")\n",
    "    \n",
    "    if len(tables_in_namespace) == 0:\n",
    "        print(\"  No tables found\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error listing tables: {e}\")\n",
    "\n",
    "# Test table accessibility\n",
    "try:\n",
    "    test_table = catalog.load_table(table_name)\n",
    "    print(\"\\nTable accessibility test: SUCCESS\")\n",
    "    print(\"Table can be loaded and accessed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\nTable accessibility test: FAILED\")\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nTable Creation Summary:\")\n",
    "print(f\"- Namespace: {namespace}\")\n",
    "print(\"- Table: users\")\n",
    "print(f\"- Full name: {table_name}\")\n",
    "print(f\"- Schema fields: {len(user_schema.fields)}\")\n",
    "print(f\"- Partition fields: {len(partition_spec.fields)}\")\n",
    "print(\"- Status: Ready for data operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps-section",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The table has been successfully created and is ready for data operations. Here's what you can do next:\n",
    "\n",
    "### Immediate Next Steps:\n",
    "1. **Insert Data**: Add user records to the table\n",
    "2. **Query Data**: Read and filter user information\n",
    "3. **Update Records**: Modify existing user data\n",
    "4. **Schema Evolution**: Add new columns as requirements change\n",
    "\n",
    "### Best Practices for Production:\n",
    "1. **Monitor Performance**: Track query performance and partition efficiency\n",
    "2. **Data Governance**: Implement access controls and data quality checks\n",
    "3. **Maintenance**: Regular compaction and snapshot cleanup\n",
    "4. **Backup Strategy**: Plan for disaster recovery and data retention\n",
    "\n",
    "### Advanced Features to Explore:\n",
    "- **Time Travel**: Query historical versions of data\n",
    "- **Schema Evolution**: Add, rename, or remove columns\n",
    "- **Partition Evolution**: Change partitioning strategy over time\n",
    "- **Snapshot Management**: Control table versions and history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete process of creating an Apache Iceberg table:\n",
    "\n",
    "### What We Accomplished:\n",
    "1. **Catalog Connection**: Connected to Iceberg REST catalog\n",
    "2. **Namespace Management**: Created logical organization structure\n",
    "3. **Schema Design**: Defined table structure with appropriate data types\n",
    "4. **Partitioning Strategy**: Implemented date-based partitioning\n",
    "5. **Table Creation**: Successfully created the table with metadata\n",
    "6. **Verification**: Confirmed table accessibility and structure\n",
    "\n",
    "### Key Concepts Learned:\n",
    "- **Field IDs**: Stable identifiers for schema evolution\n",
    "- **Partition Specifications**: Performance optimization through data organization\n",
    "- **Namespace Organization**: Logical grouping of related tables\n",
    "- **Metadata Management**: How Iceberg tracks table structure\n",
    "\n",
    "### Design Decisions Made:\n",
    "- **Date Partitioning**: Optimized for time-based queries\n",
    "- **Required Fields**: Ensured data quality with non-null constraints\n",
    "- **Extensible Schema**: Left room for future field additions\n",
    "- **Efficient Types**: Chose appropriate data types for storage and performance\n",
    "\n",
    "The table is now ready for data ingestion and querying operations in subsequent notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
